clearvars;

m = 1000;
n = 2;

X = -2 + 4*rand([m, n]);
Y = sum(abs(X), 2) <= 1;

sigma = 1;
C = 1;

[ alpha, b ] = SVMtrain_QP( X, Y, C, sigma);


hold all
plot(X(Y==0,1), X(Y==0,2), '.');
plot(X(Y~=0,1), X(Y~=0,2), '.');

% set up the domain over which you want to visualize the decision
% boundary
xrange = [-2 2];
yrange = [-2 2];
% step size for how finely you want to visualize the decision boundary.
inc = 0.1;
 
% generate grid coordinates. this will be the basis of the decision
% boundary visualization.
[x, y] = meshgrid(xrange(1):inc:xrange(2), yrange(1):inc:yrange(2));
 
% size of the (x, y) image, which will also be the size of the 
% decision boundary image that is used as the plot background.
image_size = size(x);
 
xy = [x(:) y(:)]; % make (x,y) pairs as a bunch of row vectors.

numxypairs = length(xy); % number of (x,y) pairs
 
% distance measure evaluations for each (x,y) pair.
dist = [];
 
% loop through each class and calculate distance measure for each (x,y)
% from the class prototype.
for i=1:length(training),
 
    % calculate the city block distance between every (x,y) pair and
    % the sample mean of the class.
    % the sum is over the columns to produce a distance for each (x,y)
    % pair.
    disttemp = sum(abs(xy - repmat(sample_means{i}, [numxypairs 1])), 2);
 
    % concatenate the calculated distances.
    dist = [dist disttemp];
 
end
 
% for each (x,y) pair, find the class that has the smallest distance.
% this will be the min along the 2nd dimension.
[m,idx] = min(dist, [], 2);
